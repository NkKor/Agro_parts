# –£—Ç–∏–ª–∏—Ç–∞ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ —Ñ–æ—Ç–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π –∏ –ø–æ–ª–Ω—ã–π –∑–∞–ø—É—Å–∫ –≤ shell —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥, –æ–ø–∏—Å–∞–Ω–Ω—ã—Ö –Ω–∏–∂–µ
"""
–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–µ–ª—å—Ö–æ–∑-–∑–∞–ø—á–∞—Å—Ç–µ–π —Å YOLO
–ì–∏–±–∫–∏–µ —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞

CLI:
1. –û–±—ã—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–ø—Ä–æ–ø—É—Å–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö):
python src/preprocess.py --src data/raw --dst data/processed --size 384

2. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤:
python src/preprocess.py --src data/raw --dst data/processed --size 384 --force

3. –¢–µ—Å—Ç–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤:
python src/preprocess.py --src data/raw --dst data/processed --size 512 --test --limit 50

--skip-existing (–ø–∞—Ä–∞–º–µ—Ç—Ä –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) - –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–æ—Ç–æ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ, –ø–æ–∑–≤–æ–ª—è–µ—Ç –±—ã—Å—Ç—Ä–æ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
--force - –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ –∑–∞–Ω–æ–≤–æ, –≤–∫–ª—é—á–∞—è –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–æ—Ç–æ –≤ data/processed

# –í—Å–µ —ç—Ç–∏ —Ä–∞–∑–º–µ—Ä—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è ResNet50:
sizes = [224, 256, 288, 320, 384, 448, 512, 640, 768]

# –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å vs –ö–∞—á–µ—Å—Ç–≤–æ:
# 224√ó224 - –±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–æ–∂–µ—Ç —Ç–µ—Ä—è—Ç—å –¥–µ—Ç–∞–ª–∏
# 384√ó384 - –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
# 512√ó512 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
"""

import argparse
from pathlib import Path
import cv2 as cv
import numpy as np
from tqdm import tqdm
import sys
from typing import Tuple, Optional, Dict, Any
import time
import torch

class YOLOPartPreprocessor:
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–µ–ª—å—Ö–æ–∑-–∑–∞–ø—á–∞—Å—Ç–µ–π —Å YOLO"""
    
    def __init__(self, target_size: int = 384,
                 yolo_model: str = 'yolov8n.pt',
                 confidence_threshold: float = 0.25,
                 iou_threshold: float = 0.45,
                 preserve_aspect_ratio: bool = True,
                 device: str = 'auto',
                 skip_existing: bool = True):
        self.target_size = target_size
        self.confidence_threshold = confidence_threshold
        self.iou_threshold = iou_threshold
        self.preserve_aspect_ratio = preserve_aspect_ratio
        self.skip_existing = skip_existing
        
        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        if device == 'auto':
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device
        
        print(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ YOLO –º–æ–¥–µ–ª–∏
        self.yolo_model = self._load_yolo_model(yolo_model)
    
    def _load_yolo_model(self, model_name: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ YOLO –º–æ–¥–µ–ª–∏"""
        try:
            from ultralytics import YOLO
            print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ YOLO –º–æ–¥–µ–ª–∏: {model_name}")
            
            model = YOLO(model_name)
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
            model.to(self.device)
            
            print("‚úÖ YOLO –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            return model
            
        except ImportError:
            print("‚ùå –û—à–∏–±–∫–∞: –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'ultralytics' –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
            print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install ultralytics")
            sys.exit(1)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ YOLO –º–æ–¥–µ–ª–∏: {e}")
            sys.exit(1)
    
    def read_image_safe(self, path: Path) -> Optional[np.ndarray]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            with open(path, 'rb') as f:
                file_bytes = np.asarray(bytearray(f.read()), dtype=np.uint8)
                img = cv.imdecode(file_bytes, cv.IMREAD_COLOR)
            return img
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {path}: {e}")
            return None
    
    def write_image_safe(self, path: Path, img: np.ndarray) -> bool:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–ø–∏—Å—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            path.parent.mkdir(parents=True, exist_ok=True)
            is_success, buffer = cv.imencode(".jpg", img, [cv.IMWRITE_JPEG_QUALITY, 95])
            if is_success:
                with open(path, 'wb') as f:
                    f.write(buffer)
                return True
            return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ {path}: {e}")
            return False
    
    def detect_part_with_yolo(self, image: np.ndarray) -> Optional[Tuple[int, int, int, int]]:
        """
        –î–µ—Ç–µ–∫—Ü–∏—è —Å–µ–ª—å—Ö–æ–∑-–∑–∞–ø—á–∞—Å—Ç–∏ —Å –ø–æ–º–æ—â—å—é YOLO
        """
        try:
            results = self.yolo_model(
                image, 
                conf=self.confidence_threshold,
                iou=self.iou_threshold,
                device=self.device,
                verbose=False
            )
            
            if len(results) > 0:
                boxes = results[0].boxes
                
                if boxes is not None and len(boxes) > 0:
                    bboxes = boxes.xyxy.cpu().numpy()
                    confidences = boxes.conf.cpu().numpy()
                    
                    # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –±–æ–∫—Å
                    best_idx = np.argmax(confidences)
                    box = bboxes[best_idx]
                    
                    x1, y1, x2, y2 = map(int, box)
                    width = x2 - x1
                    height = y2 - y1
                    
                    # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–µ –æ—Ç—Å—Ç—É–ø—ã (30% –¥–ª—è —Å–µ–ª—å—Ö–æ–∑ –¥–µ—Ç–∞–ª–µ–π)
                    padding_x = int(width * 0.3)
                    padding_y = int(height * 0.3)
                    
                    # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                    h, w = image.shape[:2]
                    x1_padded = max(0, x1 - padding_x)
                    y1_padded = max(0, y1 - padding_y)
                    x2_padded = min(w, x2 + padding_x)
                    y2_padded = min(h, y2 + padding_y)
                    
                    final_width = x2_padded - x1_padded
                    final_height = y2_padded - y1_padded
                    
                    return (x1_padded, y1_padded, final_width, final_height)
            
            return None
            
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ YOLO –¥–µ—Ç–µ–∫—Ü–∏–∏: {e}")
            return None
    
    def enhance_image_quality(self, image: np.ndarray) -> np.ndarray:
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è —Å–µ–ª—å—Ö–æ–∑-–¥–µ—Ç–∞–ª–µ–π"""
        try:
            h, w = image.shape[:2]
            min_dim = min(h, w)
            
            if min_dim < 100:
                enhanced = cv.bilateralFilter(image, 5, 30, 30)
            elif min_dim < 200:
                lab = cv.cvtColor(image, cv.COLOR_BGR2LAB)
                l, a, b = cv.split(lab)
                clahe = cv.createCLAHE(clipLimit=2.5, tileGridSize=(6, 6))
                l = clahe.apply(l)
                enhanced = cv.merge([l, a, b])
                enhanced = cv.cvtColor(enhanced, cv.COLOR_LAB2BGR)
                enhanced = cv.bilateralFilter(enhanced, 7, 50, 50)
            else:
                lab = cv.cvtColor(image, cv.COLOR_BGR2LAB)
                l, a, b = cv.split(lab)
                clahe = cv.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
                l = clahe.apply(l)
                enhanced = cv.merge([l, a, b])
                enhanced = cv.cvtColor(enhanced, cv.COLOR_LAB2BGR)
                enhanced = cv.bilateralFilter(enhanced, 9, 75, 75)
            
            if min_dim > 150:
                kernel = np.array([[-1, -1, -1],
                                  [-1,  9, -1],
                                  [-1, -1, -1]])
                enhanced = cv.filter2D(enhanced, -1, kernel)
            
            return enhanced
            
        except Exception:
            return image
    
    def resize_with_padding_or_crop(self, image: np.ndarray) -> np.ndarray:
        """–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Å padding –∏–ª–∏ –æ–±—Ä–µ–∑–∫–æ–π"""
        h, w = image.shape[:2]
        
        if self.preserve_aspect_ratio:
            scale = self.target_size / max(h, w)
            new_w = int(w * scale)
            new_h = int(h * scale)
            
            # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä
            if scale > 1:
                resized = cv.resize(image, (new_w, new_h), interpolation=cv.INTER_LANCZOS4)
            elif scale < 0.5:
                resized = cv.resize(image, (new_w, new_h), interpolation=cv.INTER_AREA)
            else:
                resized = cv.resize(image, (new_w, new_h), interpolation=cv.INTER_CUBIC)
            
            # –î–æ–±–∞–≤–ª—è–µ–º padding
            top = (self.target_size - new_h) // 2
            bottom = self.target_size - new_h - top
            left = (self.target_size - new_w) // 2
            right = self.target_size - new_w - left
            
            padded = cv.copyMakeBorder(
                resized, top, bottom, left, right, 
                cv.BORDER_CONSTANT, value=[128, 128, 128]
            )
            
            return padded
        else:
            return cv.resize(image, (self.target_size, self.target_size), 
                           interpolation=cv.INTER_LANCZOS4)
    
    def preprocess_single_image(self, src_path: Path, dst_path: Path) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        stats = {
            'success': False,
            'operations': [],
            'original_size': None,
            'final_size': None,
            'detection_confidence': 0.0,
            'processing_time': 0.0,
            'skipped': False
        }
        
        start_time = time.time()
        
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            if self.skip_existing and dst_path.exists():
                stats['skipped'] = True
                stats['success'] = True
                stats['operations'].append('skipped_existing')
                stats['processing_time'] = time.time() - start_time
                return stats
            
            # –ß—Ç–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image = self.read_image_safe(src_path)
            if image is None:
                stats['error'] = 'read_failed'
                stats['processing_time'] = time.time() - start_time
                return stats
            
            stats['original_size'] = f"{image.shape[1]}x{image.shape[0]}"
            
            # –î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–∞
            bbox = self.detect_part_with_yolo(image)
            
            if bbox is not None:
                x, y, w, h = bbox
                cropped = image[y:y+h, x:x+w]
                stats['operations'].append('yolo_detection')
                stats['detection_confidence'] = 0.5
            else:
                # Fallback: —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ –¥–æ –∫–≤–∞–¥—Ä–∞—Ç–∞
                h_img, w_img = image.shape[:2]
                size = min(h_img, w_img)
                y_start = (h_img - size) // 2
                x_start = (w_img - size) // 2
                cropped = image[y_start:y_start+size, x_start:x_start+size]
                stats['operations'].append('center_crop')
                stats['detection_confidence'] = 0.0
            
            # –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞
            enhanced = self.enhance_image_quality(cropped)
            stats['operations'].append('quality_enhancement')
            
            # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞
            final_image = self.resize_with_padding_or_crop(enhanced)
            stats['operations'].append('resize')
            stats['final_size'] = f"{final_image.shape[1]}x{final_image.shape[0]}"
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            success = self.write_image_safe(dst_path, final_image)
            stats['success'] = success
            
            if not success:
                stats['error'] = 'save_failed'
                
        except Exception as e:
            stats['error'] = str(e)
            stats['success'] = False
        
        stats['processing_time'] = time.time() - start_time
        return stats
    
    def get_pending_images(self, src_root: Path, dst_root: Path) -> list:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, —Ç—Ä–µ–±—É—é—â–∏—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        files = list(src_root.rglob("*"))
        images = [p for p in files if p.suffix.lower() in [".jpg", ".jpeg", ".png"]]
        
        if not self.skip_existing:
            return images
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è: —Ç–æ–ª—å–∫–æ —Ç–µ, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        pending_images = []
        for src_path in images:
            rel_path = src_path.relative_to(src_root)
            dst_path = dst_root / rel_path.with_suffix(".jpg")
            if not dst_path.exists():
                pending_images.append(src_path)
        
        return pending_images
    
    def process_dataset(self, src_root: Path, dst_root: Path, 
                       test_mode: bool = False, 
                       test_limit: int = 100) -> Dict[str, int]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å –ø—Ä–æ–ø—É—Å–∫–æ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤
        """
        print(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å YOLO: {src_root} ‚Üí {dst_root}")
        print(f"üìè –¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä: {self.target_size}√ó{self.target_size}")
        print(f"üéØ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–π: {'–î–∞' if self.preserve_aspect_ratio else '–ù–µ—Ç'}")
        print(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö: {'–î–∞' if self.skip_existing else '–ù–µ—Ç'}")
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        all_images = list(src_root.rglob("*"))
        all_images = [p for p in all_images if p.suffix.lower() in [".jpg", ".jpeg", ".png"]]
        total_images = len(all_images)
        
        pending_images = self.get_pending_images(src_root, dst_root)
        pending_count = len(pending_images)
        
        print(f"üìä –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {total_images}")
        print(f"üìã –¢—Ä–µ–±—É—é—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏: {pending_count}")
        
        if self.skip_existing and pending_count == 0:
            print("‚úÖ –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
            return {
                'processed': 0,
                'successful': 0,
                'failed': 0,
                'read_errors': 0,
                'save_errors': 0,
                'detection_success': 0,
                'skipped': total_images,
                'total_processing_time': 0.0
            }
        
        # –¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º
        if test_mode:
            # –î–ª—è —Ç–µ—Å—Ç–∞ –±–µ—Ä–µ–º –∏–∑ pending_images
            images_to_process = pending_images[:test_limit] if pending_images else all_images[:test_limit]
            print(f"üß™ –¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–≤—ã—Ö {len(images_to_process)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        else:
            images_to_process = pending_images if self.skip_existing else all_images
            print(f"üöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(images_to_process)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = {
            'processed': 0,
            'successful': 0,
            'failed': 0,
            'read_errors': 0,
            'save_errors': 0,
            'detection_success': 0,
            'skipped': total_images - pending_count if self.skip_existing else 0,
            'total_processing_time': 0.0
        }
        
        pbar = tqdm(images_to_process, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞", unit="img")
        
        for src_path in pbar:
            rel_path = src_path.relative_to(src_root)
            dst_path = dst_root / rel_path.with_suffix(".jpg")
            
            result = self.preprocess_single_image(src_path, dst_path)
            
            stats['processed'] += 1
            stats['total_processing_time'] += result.get('processing_time', 0)
            
            if result['success']:
                if result.get('skipped', False):
                    # –£–∂–µ –ø–æ–¥—Å—á–∏—Ç–∞–Ω–æ –≤ 'skipped'
                    pass
                else:
                    stats['successful'] += 1
                    if 'yolo_detection' in result.get('operations', []):
                        stats['detection_success'] += 1
            else:
                stats['failed'] += 1
                if result.get('error') == 'read_failed':
                    stats['read_errors'] += 1
                elif result.get('error') == 'save_failed':
                    stats['save_errors'] += 1
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
            pbar.set_postfix({
                '–ù–æ–≤—ã–µ': stats['successful'],
                'YOLO': stats['detection_success'],
                '–û—à–∏–±–∫–∞': stats['failed'],
                '–ü—Ä–æ–ø—É—â': stats['skipped']
            })
        
        return stats

def main():
    parser = argparse.ArgumentParser(
        description="–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–µ–ª—å—Ö–æ–∑-–∑–∞–ø—á–∞—Å—Ç–µ–π —Å YOLO",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ä–∞–∑–º–µ—Ä—ã:
  224 - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π (–±—ã—Å—Ç—Ä–æ, —ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏)
  384 - –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
  512 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ

–ü—Ä–∏–º–µ—Ä—ã:
  %(prog)s --src data/raw --dst data/processed --size 384
  %(prog)s --src data/raw --dst data/processed --size 384 --test --limit 100
  %(prog)s --src data/raw --dst data/processed --force  # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ –∑–∞–Ω–æ–≤–æ
        """
    )
    
    parser.add_argument("--src", type=str, required=True,
                       help="–ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º")
    parser.add_argument("--dst", type=str, required=True,
                       help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    parser.add_argument("--test", action="store_true",
                       help="–¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º")
    parser.add_argument("--limit", type=int, default=100,
                       help="–õ–∏–º–∏—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Ç–µ—Å—Ç–∞ (default: 100)")
    parser.add_argument("--size", type=int, default=384,
                       help="–¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (default: 384)")
    parser.add_argument("--model", type=str, default='yolov8n.pt',
                       help="YOLO –º–æ–¥–µ–ª—å (default: yolov8n.pt)")
    parser.add_argument("--conf", type=float, default=0.25,
                       help="–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (default: 0.25)")
    parser.add_argument("--iou", type=float, default=0.45,
                       help="–ü–æ—Ä–æ–≥ IoU (default: 0.45)")
    parser.add_argument("--preserve-aspect", action="store_true", default=True,
                       help="–°–æ—Ö—Ä–∞–Ω—è—Ç—å –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (default: True)")
    parser.add_argument("--no-preserve-aspect", dest="preserve_aspect", action="store_false",
                       help="–ù–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ (—Ä–∞—Å—Ç—è–Ω—É—Ç—å –¥–æ –∫–≤–∞–¥—Ä–∞—Ç–∞)")
    parser.add_argument("--device", type=str, default='auto',
                       help="–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: 'cpu', 'cuda', 'cuda:0', 'auto' (default: auto)")
    parser.add_argument("--force", action="store_true",
                       help="–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã –∑–∞–Ω–æ–≤–æ (–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ)")
    parser.add_argument("--skip-existing", action="store_true", default=True,
                       help="–ü—Ä–æ–ø—É—Å–∫–∞—Ç—å —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (default: True)")
    
    args = parser.parse_args()
    
    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω --force, –æ—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–ø—É—Å–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö
    if args.force:
        args.skip_existing = False
    
    src_path = Path(args.src)
    dst_path = Path(args.dst)
    
    if not src_path.exists():
        print(f"‚ùå –ò—Å—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {src_path}")
        return 1
    
    print("üöú –ù–∞—á–∞–ª–æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–µ–ª—å—Ö–æ–∑-–∑–∞–ø—á–∞—Å—Ç–µ–π (YOLO)")
    print("=" * 70)
    print(f"üìè –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {args.size}√ó{args.size}")
    print(f"üéØ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–π: {'–î–∞' if args.preserve_aspect else '–ù–µ—Ç'}")
    print(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö: {'–î–∞' if args.skip_existing else '–ù–µ—Ç'}")
    print(f"üîß –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {args.device}")
    
    preprocessor = YOLOPartPreprocessor(
        target_size=args.size,
        yolo_model=args.model,
        confidence_threshold=args.conf,
        iou_threshold=args.iou,
        preserve_aspect_ratio=args.preserve_aspect,
        device=args.device,
        skip_existing=args.skip_existing
    )
    
    start_time = time.time()
    stats = preprocessor.process_dataset(
        src_path, dst_path, 
        test_mode=args.test, 
        test_limit=args.limit
    )
    total_time = time.time() - start_time
    
    print("\n" + "=" * 70)
    print("üèÅ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–†–ê–ë–û–¢–ö–ò")
    print("=" * 70)
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['successful']}")
    print(f"‚ùå –û—à–∏–±–æ–∫: {stats['failed']}")
    print(f"   - –û—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è: {stats['read_errors']}")
    print(f"   - –û—à–∏–±–∫–∏ –∑–∞–ø–∏—Å–∏: {stats['save_errors']}")
    print(f"üéØ –£—Å–ø–µ—à–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è YOLO: {stats['detection_success']}")
    if args.skip_existing:
        print(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö: {stats['skipped']}")
    print(f"üìä –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed']}")
    
    if stats['processed'] > 0:
        success_rate = stats['successful'] / stats['processed'] * 100
        detection_rate = stats['detection_success'] / stats['processed'] * 100
        print(f"üìà –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {success_rate:.1f}%")
        print(f"üéØ –ü—Ä–æ—Ü–µ–Ω—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏: {detection_rate:.1f}%")
        
        if stats['processed'] > 0:
            avg_time = stats['total_processing_time'] / stats['processed']
            print(f"‚è±Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {avg_time:.2f} —Å–µ–∫")
    
    print(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_time:.2f} —Å–µ–∫")
    
    if stats['successful'] > 0:
        images_per_second = stats['successful'] / total_time if total_time > 0 else 0
        print(f"‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {images_per_second:.2f} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π/—Å–µ–∫")
    
    print(f"\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {dst_path}")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    if args.size < 256:
        print("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        print("   ‚ö†Ô∏è  –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ä ‚â• 384 –¥–ª—è —Å–µ–ª—å—Ö–æ–∑-–∑–∞–ø—á–∞—Å—Ç–µ–π")
        print("   üéØ 384√ó384 - –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–æ/–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")
        print("   üìà 512√ó512 - –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ/–Ω–∏–∂–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑-–∑–∞ –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ CUDA")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())