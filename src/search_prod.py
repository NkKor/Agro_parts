import argparse, cv2 as cv, numpy as np, faiss, torch, torchvision.transforms as T
from pathlib import Path
from encoder import ResNet50Encoder
from config import (IDX_DIR, EMB_DIR, DEVICE, TARGET_SIZE, PAD_RATIO, MIN_OBJ_AREA, TOPK_DEFAULT)
from utils_cv import find_largest_foreground_bbox, pad_bbox, center_square_crop, resize_high_quality

# –∑–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–æ–≤ –∏ id
CENTROIDS = np.load(EMB_DIR/"centroids.npy")
CENTROID_IDS = np.load(EMB_DIR/"centroid_ids.npy", allow_pickle=True)
IDX_C = faiss.read_index(str(IDX_DIR/"faiss_centroid.bin"))

# per-image –¥–ª—è re-rank (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
PERIMG = np.load(EMB_DIR/"per_image.npy")
PERIMG_IDS = np.load(EMB_DIR/"part_ids.npy", allow_pickle=True)
IDX_X = faiss.read_index(str(IDX_DIR/"faiss_img.bin"))

transform = T.Compose([
    T.ToTensor(),
    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
])

@torch.no_grad()
def embed_bgr(img_bgr, model):
    # –±—ã—Å—Ç—Ä—ã–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å (–∫–∞–∫ –≤ –æ—Ñ—Ñ–ª–∞–π–Ω–µ)
    bbox = find_largest_foreground_bbox(img_bgr, min_area_ratio=MIN_OBJ_AREA)
    if bbox is not None:
        bbox = pad_bbox(bbox, img_bgr.shape, pad_ratio=PAD_RATIO)
        x1,y1,x2,y2 = bbox
        img_bgr = img_bgr[y1:y2, x1:x2]
    else:
        img_bgr = center_square_crop(img_bgr)
    img_bgr = resize_high_quality(img_bgr, TARGET_SIZE)

    # –≤ —Ç–µ–Ω–∑–æ—Ä
    import torchvision.transforms.functional as F
    img_rgb = cv.cvtColor(img_bgr, cv.COLOR_BGR2RGB)
    pil = F.to_pil_image(img_rgb)
    x = transform(pil).unsqueeze(0).to(DEVICE)
    emb = model(x).cpu().numpy()  # L2-–Ω–æ—Ä–º–∞ —É–∂–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ –≤ encoder
    return emb

def search(query_path: str, topk=TOPK_DEFAULT, rerank_per_image=True, per_image_k=200):
    model = ResNet50Encoder().to(DEVICE).eval()

    img = cv.imread(query_path, cv.IMREAD_COLOR)
    emb = embed_bgr(img, model)  # [1, D]

    # 1) –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ —Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞–º
    D, I = IDX_C.search(emb.astype("float32"), topk if not rerank_per_image else per_image_k)
    cand_part_ids = [CENTROID_IDS[i] for i in I[0]]

    if not rerank_per_image:
        return list(zip(cand_part_ids, D[0].tolist()))

    # 2) –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ per-image —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    # —Å–æ–±–µ—Ä—ë–º –∏–Ω–¥–µ–∫—Å—ã –≤—Å–µ—Ö —Ñ–æ—Ç–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    cand_mask = np.isin(PERIMG_IDS, np.array(cand_part_ids, dtype=object))
    cand_vectors = PERIMG[cand_mask]
    # –∫–æ—Å–∏–Ω—É—Å–Ω–∞—è –±–ª–∏–∑–æ—Å—Ç—å = dot, —Ç.–∫. L2-–Ω–æ—Ä–º—ã = 1
    sims = (emb @ cand_vectors.T).ravel()  # [M]
    # –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ part_id: max –∏–ª–∏ mean; –±–µ—Ä—ë–º max –¥–ª—è ¬´–ª—É—á—à–µ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è¬ª
    cand_ids = PERIMG_IDS[cand_mask]
    best = {}
    for sim, pid in zip(sims, cand_ids):
        best[pid] = max(best.get(pid, -1.0), float(sim))
    # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ sim —É–±—ã–≤.
    ranked = sorted(best.items(), key=lambda x: x[1], reverse=True)[:topk]
    # –≤–µ—Ä–Ω—ë–º –∫–∞–∫ (part_id, similarity)
    return ranked

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--query", required=True, type=str)
    ap.add_argument("--topk", type=int, default=TOPK_DEFAULT)
    ap.add_argument("--no_rerank", action="store_true")
    args = ap.parse_args()

    results = search(args.query, topk=args.topk, rerank_per_image=not args.no_rerank)
    print("üîé –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    for pid, score in results:
        print(f"{pid}\t{score:.4f}")

if __name__ == "__main__":
    main()
